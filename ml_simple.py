import os
import json
import logging
from typing import List, Dict, Any
from pathlib import Path
from dotenv import load_dotenv
from datetime import datetime

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö —Å—Ä–µ–¥—ã —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
load_dotenv()

# –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF
from pdfminer.high_level import extract_text

# OpenAI
from openai import OpenAI

# –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logger = logging.getLogger(__name__)

# OpenAI –∫–ª–∏–µ–Ω—Ç
openai_client = None

def load_models():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π"""
    global openai_client
    
    logger.info("Loading OpenAI client...")
    
    # OpenAI –∫–ª–∏–µ–Ω—Ç
    api_key = os.environ.get('OPENAI_API_KEY')
    if not api_key:
        raise ValueError("OPENAI_API_KEY environment variable not set")
    openai_client = OpenAI(api_key=api_key)
    
    logger.info("OpenAI client loaded successfully")

try:
    load_models()
except Exception as e:
    logger.warning(f"Models not loaded on import: {str(e)}")

def extract_text_from_pdf(filepath: str) -> str:
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF"""
    try:
        text = extract_text(filepath)
        return text.strip()
    except Exception as e:
        logger.error(f"Error extracting text from PDF: {str(e)}")
        raise

def generate_simple_analysis(text: str) -> Dict[str, Any]:
    """–ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é GPT"""
    try:
        if not openai_client:
            load_models()
        
        # –õ–∏–º–∏—Ç —Ç–µ–∫—Å—Ç–∞ –¥–ª—è API
        max_chars = 50000
        if len(text) > max_chars:
            text = text[:max_chars] + "..."
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —É—á–µ–±–Ω—ã–π —Ç–µ–∫—Å—Ç –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑.

–í–µ—Ä–Ω–∏ JSON –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "summary": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
  "main_topics": [
    {{
      "title": "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã",
      "summary": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–µ–º—ã"
    }}
  ],
  "flashcards": [
    {{
      "q": "–í–æ–ø—Ä–æ—Å",
      "a": "–û—Ç–≤–µ—Ç",
      "type": "concept"
    }}
  ]
}}

–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{text}"""
        
        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤. –°–æ–∑–¥–∞–≤–∞–π –∫—Ä–∞—Ç–∫–∏–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –∞–Ω–∞–ª–∏–∑."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=2000,
            response_format={"type": "json_object"}
        )
        
        analysis = json.loads(response.choices[0].message.content)
        
        return analysis
        
    except Exception as e:
        logger.error(f"Error in simple analysis: {str(e)}")
        return {
            "summary": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç",
            "main_topics": [{"title": "–û—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞", "summary": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞"}],
            "flashcards": [{"q": "–ß—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–æ–∫—É–º–µ–Ω—Ç?", "a": "–£—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª", "type": "concept"}]
        }

def get_chat_response(user_message: str, full_text: str, result_data: Dict[str, Any]) -> str:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç ChatGPT –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –ª–µ–∫—Ü–∏–∏"""
    try:
        if not openai_client:
            load_models()
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        max_context_chars = 100000
        context_text = full_text[:max_context_chars] if len(full_text) > max_context_chars else full_text
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
        summary = result_data.get('summary', '')
        filename = result_data.get('filename', '–ª–µ–∫—Ü–∏—è')
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è ChatGPT
        system_prompt = f"""–¢—ã - AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å—Ç—É–¥–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–π –ª–µ–∫—Ü–∏–∏.

–ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –ª–µ–∫—Ü–∏–∏
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –ª–µ–∫—Ü–∏–∏, —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
3. –î–∞–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏ –ø–æ–ª–µ–∑–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
4. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–º–µ—Ä—ã –∏–∑ –ª–µ–∫—Ü–∏–∏ –∫–æ–≥–¥–∞ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ
5. –ü–æ–º–æ–≥–∞–π –ø–æ–Ω—è—Ç—å —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
6. –ï—Å–ª–∏ —Å—Ç—É–¥–µ–Ω—Ç –ø—Ä–æ—Å–∏—Ç –æ–±—ä—è—Å–Ω–∏—Ç—å —á—Ç–æ-—Ç–æ –ø–æ–¥—Ä–æ–±–Ω–µ–µ, –∏—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –ª–µ–∫—Ü–∏–∏

–ù–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞: {filename}

–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ª–µ–∫—Ü–∏–∏:
{summary[:500]}..."""

        user_prompt = f"""–í–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞: {user_message}

–¢–µ–∫—Å—Ç –ª–µ–∫—Ü–∏–∏ –¥–ª—è —Å–ø—Ä–∞–≤–∫–∏:
{context_text}

–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å —Å—Ç—É–¥–µ–Ω—Ç–∞, –æ–ø–∏—Ä–∞—è—Å—å –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –ª–µ–∫—Ü–∏–∏."""

        response = openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=1500
        )
        
        ai_response = response.choices[0].message.content.strip()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∏—Å—Ç–æ—á–Ω–∏–∫–µ
        if len(ai_response) > 50:  # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–π
            ai_response += f"\n\nüí° *–û—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–µ –ª–µ–∫—Ü–∏–∏ \"{filename}\"*"
        
        return ai_response
        
    except Exception as e:
        logger.error(f"Error getting chat response: {str(e)}")
        return f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}"

def process_file(filepath: str, filename: str, page_range: str = None) -> Dict[str, Any]:
    """–ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞"""
    try:
        logger.info(f"Starting simple processing for: {filename}")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
        file_ext = Path(filename).suffix.lower()
        
        if file_ext == '.pdf':
            text = extract_text_from_pdf(filepath)
        else:
            raise ValueError(f"Unsupported file type: {file_ext}")
        
        if not text or len(text.strip()) < 50:
            raise ValueError("Extracted text is too short or empty")
        
        logger.info(f"Extracted {len(text)} characters of text")
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —Å GPT
        analysis = generate_simple_analysis(text)
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            "topics_data": {
                "main_topics": analysis.get("main_topics", []),
                "concept_map": {"relationships": []},
                "learning_objectives": [],
                "prerequisites": []
            },
            "summary": analysis.get("summary", ""),
            "flashcards": analysis.get("flashcards", []),
            "mind_map": {},
            "study_plan": {
                "total_hours": 2.0,
                "sessions": [],
                "milestones": [],
                "success_metrics": {},
                "repetition_schedule": {},
                "completion_date": ""
            },
            "quality_assessment": {"overall_score": 0.8},
            "full_text": text,  # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è —á–∞—Ç–∞
            "video_segments": [],
            "key_moments": [],
            "metadata": {
                "filename": filename,
                "file_type": file_ext,
                "text_length": len(text),
                "processing_date": datetime.now().isoformat(),
                "processing_time": 1.0,
                "speed_optimized": True
            }
        }
        
        logger.info(f"Simple processing complete for: {filename}")
        
        return result
        
    except Exception as e:
        logger.error(f"Error in simple processing: {str(e)}")
        raise