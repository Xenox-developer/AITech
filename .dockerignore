# .dockerignore
venv/
__pycache__/
*.pyc
*.pyo
*.pyd
.Python
env/
.env.local
.env.*.local
pip-log.txt
pip-delete-this-directory.txt
.tox/
.coverage
.coverage.*
.cache
.pytest_cache/
nosetests.xml
coverage.xml
*.cover
*.log
.git
.gitignore
.mypy_cache
.pytest_cache
.hypothesis
.idea
.vscode
*.swp
*.swo
*~
.DS_Store
uploads/*
data/*.db
*.sqlite
*.db-journal
README.md
LICENSE
docker-compose*.yml
Dockerfile*
.dockerignore

---

# docker-compose.dev.yml - Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: ai_study_app_dev
    ports:
      - "5000:5000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - FLASK_ENV=development
      - FLASK_DEBUG=1
      - SECRET_KEY=dev-secret-key
    volumes:
      - .:/app  # ĞœĞ¾Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ĞµÑÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚ Ğ´Ğ»Ñ hot-reload
      - /app/__pycache__
      - /app/.pytest_cache
      - whisper_cache:/home/appuser/.cache/whisper
      - huggingface_cache:/home/appuser/.cache/huggingface
    command: ["python", "app.py"]  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Flask dev server
    stdin_open: true
    tty: true

volumes:
  whisper_cache:
  huggingface_cache:

---

# docker-compose.gpu.yml - Ğ´Ğ»Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ñ GPU
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    runtime: nvidia
    container_name: ai_study_app_gpu
    ports:
      - "5000:5000"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - MAX_UPLOAD_MB=${MAX_UPLOAD_MB:-500}
      - FLASK_ENV=${FLASK_ENV:-production}
      - SECRET_KEY=${SECRET_KEY}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - ./uploads:/app/uploads
      - ./data:/app/data
      - whisper_cache:/home/appuser/.cache/whisper
      - huggingface_cache:/home/appuser/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

volumes:
  whisper_cache:
    driver: local
  huggingface_cache:
    driver: local

---

# nginx.conf - ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Nginx
events {
    worker_connections 1024;
}

http {
    upstream app {
        server app:5000;
    }

    server {
        listen 80;
        server_name localhost;
        client_max_body_size 200M;

        location / {
            proxy_pass http://app;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_read_timeout 300s;
            proxy_connect_timeout 75s;
        }

        location /static {
            alias /app/static;
            expires 30d;
            add_header Cache-Control "public, immutable";
        }
    }
}

---

# build.sh - ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ ÑĞ±Ğ¾Ñ€ĞºĞ¸
#!/bin/bash

echo "ğŸš€ Building AI Study MVP Docker images..."

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ°Ğ»Ğ¸Ñ‡Ğ¸Ñ .env Ñ„Ğ°Ğ¹Ğ»Ğ°
if [ ! -f .env ]; then
    echo "âŒ .env file not found! Creating from example..."
    cp .env.example .env
    echo "âš ï¸  Please edit .env file and add your OPENAI_API_KEY"
    exit 1
fi

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° OPENAI_API_KEY
source .env
if [ -z "$OPENAI_API_KEY" ]; then
    echo "âŒ OPENAI_API_KEY not set in .env file!"
    exit 1
fi

# Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ñ‹Ñ… Ğ´Ğ¸Ñ€ĞµĞºÑ‚Ğ¾Ñ€Ğ¸Ğ¹
mkdir -p uploads data

# Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° ÑĞ±Ğ¾Ñ€ĞºĞ¸
echo "Select build mode:"
echo "1) CPU only (default)"
echo "2) GPU support"
echo "3) Development mode"
read -p "Enter choice [1-3]: " choice

case $choice in
    2)
        echo "ğŸ“¦ Building GPU version..."
        docker-compose -f docker-compose.gpu.yml build
        ;;
    3)
        echo "ğŸ“¦ Building development version..."
        docker-compose -f docker-compose.dev.yml build
        ;;
    *)
        echo "ğŸ“¦ Building CPU version..."
        docker-compose build
        ;;
esac

echo "âœ… Build complete!"

---

# run-docker.sh - ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
#!/bin/bash

echo "ğŸš€ Starting AI Study MVP..."

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Docker
if ! command -v docker &> /dev/null; then
    echo "âŒ Docker not found! Please install Docker first."
    exit 1
fi

# ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° docker-compose
if ! command -v docker-compose &> /dev/null; then
    echo "âŒ docker-compose not found! Please install docker-compose first."
    exit 1
fi

# Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°
echo "Select run mode:"
echo "1) CPU only (default)"
echo "2) GPU support"
echo "3) Development mode"
echo "4) Production with Nginx"
read -p "Enter choice [1-4]: " choice

case $choice in
    2)
        echo "ğŸš€ Starting with GPU support..."
        docker-compose -f docker-compose.gpu.yml up -d
        ;;
    3)
        echo "ğŸš€ Starting in development mode..."
        docker-compose -f docker-compose.dev.yml up
        ;;
    4)
        echo "ğŸš€ Starting in production mode with Nginx..."
        docker-compose --profile production up -d
        ;;
    *)
        echo "ğŸš€ Starting with CPU only..."
        docker-compose up -d
        ;;
esac

echo "âœ… Application started!"
echo "ğŸŒ Access the application at: http://localhost:5000"
echo "ğŸ“Š View logs: docker-compose logs -f app"
echo "ğŸ›‘ Stop: docker-compose down"