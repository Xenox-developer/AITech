#!/usr/bin/env python3
"""
–≠–ö–°–ü–†–ï–°–°-–û–ë–†–ê–ë–û–¢–ß–ò–ö –í–ò–î–ï–û
–¶–µ–ª—å: –æ–±—Ä–∞–±–æ—Ç–∫–∞ 5-–º–∏–Ω—É—Ç–Ω–æ–≥–æ –≤–∏–¥–µ–æ –∑–∞ 1-2 –º–∏–Ω—É—Ç—ã –º–∞–∫—Å–∏–º—É–º
"""

import os
import json
import time
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any
from dotenv import load_dotenv
import whisperx
import torch
from openai import OpenAI
from collections import Counter
import re

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

logger = logging.getLogger(__name__)

class FastVideoProcessor:
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.compute_type = "float16" if self.device == "cuda" else "int8"
        self.whisper_model = None
        self.openai_client = None
        self._load_models()
    
    def _load_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å Whisper
            logger.info("Loading FAST Whisper model...")
            self.whisper_model = whisperx.load_model("base", self.device, compute_type=self.compute_type)
            logger.info("Fast Whisper model loaded")
            
            # OpenAI –∫–ª–∏–µ–Ω—Ç
            api_key = os.environ.get('OPENAI_API_KEY')
            if api_key:
                self.openai_client = OpenAI(api_key=api_key)
                logger.info("OpenAI client initialized")
            else:
                logger.warning("No OpenAI API key - will use fallback methods")
                
        except Exception as e:
            logger.error(f"Error loading models: {e}")
            raise
    
    def process_video_express(self, filepath: str, filename: str) -> Dict[str, Any]:
        """–≠–ö–°–ü–†–ï–°–°-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –∑–∞ 1-2 –º–∏–Ω—É—Ç—ã"""
        start_time = time.time()
        logger.info(f"üöÄ –≠–ö–°–ü–†–ï–°–°-—Ä–µ–∂–∏–º: {filename}")
        
        try:
            # –≠–¢–ê–ü 1: –ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (30-60 —Å–µ–∫)
            logger.info("‚ö° –≠—Ç–∞–ø 1/4: –ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è...")
            transcription_start = time.time()
            video_data = self._transcribe_express(filepath)
            transcription_time = time.time() - transcription_start
            logger.info(f"‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞ {transcription_time:.1f}—Å")
            
            text = video_data['full_text']
            if len(text.strip()) < 20:
                raise ValueError("–°–ª–∏—à–∫–æ–º –º–∞–ª–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            
            # –≠–¢–ê–ü 2: –≠–∫—Å–ø—Ä–µ—Å—Å-–∞–Ω–∞–ª–∏–∑ —Ç–µ–º (15-30 —Å–µ–∫)
            logger.info("‚ö° –≠—Ç–∞–ø 2/4: –ê–Ω–∞–ª–∏–∑ —Ç–µ–º...")
            topics_start = time.time()
            topics_data = self._extract_topics_express(text)
            topics_time = time.time() - topics_start
            logger.info(f"‚úÖ –¢–µ–º—ã –∑–∞ {topics_time:.1f}—Å")
            
            # –≠–¢–ê–ü 3: –ë—ã—Å—Ç—Ä–æ–µ —Ä–µ–∑—é–º–µ (10-20 —Å–µ–∫)
            logger.info("‚ö° –≠—Ç–∞–ø 3/4: –†–µ–∑—é–º–µ...")
            summary_start = time.time()
            summary = self._generate_summary_express(text)
            summary_time = time.time() - summary_start
            logger.info(f"‚úÖ –†–µ–∑—é–º–µ –∑–∞ {summary_time:.1f}—Å")
            
            # –≠–¢–ê–ü 4: –≠–∫—Å–ø—Ä–µ—Å—Å —Ñ–ª–µ—à-–∫–∞—Ä—Ç—ã (10-20 —Å–µ–∫)
            logger.info("‚ö° –≠—Ç–∞–ø 4/4: –§–ª–µ—à-–∫–∞—Ä—Ç—ã...")
            cards_start = time.time()
            flashcards = self._generate_flashcards_express(text, topics_data['main_topics'])
            cards_time = time.time() - cards_start
            logger.info(f"‚úÖ –§–ª–µ—à-–∫–∞—Ä—Ç—ã –∑–∞ {cards_time:.1f}—Å")
            
            # –ë—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ
            mind_map = self._generate_mind_map_simple(topics_data['main_topics'])
            study_plan = self._generate_study_plan_simple(topics_data['main_topics'], len(flashcards))
            quality = self._assess_quality_simple(text, topics_data['main_topics'])
            
            total_time = time.time() - start_time
            
            result = {
                "topics_data": topics_data,
                "summary": summary,
                "flashcards": flashcards,
                "mind_map": mind_map,
                "study_plan": study_plan,
                "quality_assessment": quality,
                "video_segments": video_data.get('segments', []),
                "key_moments": video_data.get('key_moments', []),
                "metadata": {
                    "filename": filename,
                    "file_type": ".mp4",
                    "text_length": len(text),
                    "processing_date": datetime.now().isoformat(),
                    "processing_time": round(total_time, 1),
                    "express_mode": True,
                    "timing": {
                        "transcription": round(transcription_time, 1),
                        "topics": round(topics_time, 1),
                        "summary": round(summary_time, 1),
                        "flashcards": round(cards_time, 1),
                        "total": round(total_time, 1)
                    }
                }
            }
            
            logger.info(f"üéâ –≠–ö–°–ü–†–ï–°–°-–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {total_time:.1f}—Å!")
            return result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —ç–∫—Å–ø—Ä–µ—Å—Å-–æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
            raise
    
    def _transcribe_express(self, filepath: str) -> Dict[str, Any]:
        """–ë—ã—Å—Ç—Ä–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –í–°–ï–ì–û –≤–∏–¥–µ–æ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ
            audio = whisperx.load_audio(filepath)
            duration = len(audio) / 16000
            logger.info(f"üé¨ –ü–æ–ª–Ω–æ–µ –≤–∏–¥–µ–æ: {duration:.1f}—Å ({duration/60:.1f} –º–∏–Ω)")
            
            # –ù–û–í–ê–Ø –õ–û–ì–ò–ö–ê: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –≤–∏–¥–µ–æ, –Ω–æ —Å —Ä–∞–∑–Ω—ã–º–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
            if duration > 3600:  # –ë–æ–ª–µ–µ 1 —á–∞—Å–∞
                logger.info("üìö –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ (>1—á) - –∏—Å–ø–æ–ª—å–∑—É–µ–º batch_size=1 –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏")
                batch_size = 1
            elif duration > 1800:  # –ë–æ–ª–µ–µ 30 –º–∏–Ω—É—Ç
                logger.info("üìñ –î–ª–∏–Ω–Ω–æ–µ –≤–∏–¥–µ–æ (>30–º–∏–Ω) - –∏—Å–ø–æ–ª—å–∑—É–µ–º batch_size=2")
                batch_size = 2
            elif duration > 600:  # –ë–æ–ª–µ–µ 10 –º–∏–Ω—É—Ç
                logger.info("üìÑ –°—Ä–µ–¥–Ω–µ–µ –≤–∏–¥–µ–æ (>10–º–∏–Ω) - –∏—Å–ø–æ–ª—å–∑—É–µ–º batch_size=4")
                batch_size = 4
            else:
                logger.info("üìù –ö–æ—Ä–æ—Ç–∫–æ–µ –≤–∏–¥–µ–æ (<10–º–∏–Ω) - –∏—Å–ø–æ–ª—å–∑—É–µ–º batch_size=8")
                batch_size = 8
            
            # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –í–°–ï–ì–û –≤–∏–¥–µ–æ —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º batch_size
            logger.info(f"üé§ –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –≤—Å–µ {duration:.0f}—Å —Å batch_size={batch_size}")
            result = self.whisper_model.transcribe(audio, batch_size=batch_size)
            
            # –ü—Ä–æ—Å—Ç–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –±–µ–∑ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è
            segments = []
            full_text = ""
            
            for segment in result.get("segments", []):
                text = segment.get("text", "").strip()
                if text:
                    full_text += text + " "
                    segments.append({
                        "start": round(segment.get("start", 0)),
                        "end": round(segment.get("end", 0)),
                        "text": text,
                        "importance": 0.5
                    })
            
            # –ü—Ä–æ—Å—Ç—ã–µ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
            key_moments = []
            if segments:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π, —Å—Ä–µ–¥–Ω–∏–π –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–µ–≥–º–µ–Ω—Ç
                indices = [0, len(segments)//2, -1] if len(segments) > 2 else [0]
                for i in indices:
                    if i < len(segments):
                        seg = segments[i]
                        key_moments.append({
                            "time": seg["start"],
                            "description": seg["text"][:80] + "...",
                            "importance": 0.7
                        })
            
            return {
                "full_text": full_text.strip(),
                "segments": segments,
                "key_moments": key_moments,
                "language": result.get("language", "unknown"),
                "total_duration": duration
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏: {e}")
            raise
    
    def _extract_topics_express(self, text: str) -> Dict[str, Any]:
        """–≠–∫—Å–ø—Ä–µ—Å—Å-–∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º"""
        try:
            if self.openai_client and len(text) > 100:
                return self._extract_topics_with_api(text)
            else:
                return self._extract_topics_local(text)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–º: {e}")
            return self._extract_topics_local(text)
    
    def _extract_topics_with_api(self, text: str) -> Dict[str, Any]:
        """–£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º —á–µ—Ä–µ–∑ API —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
        original_length = len(text)
        logger.info(f"üìù –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç: {original_length} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –£–º–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
        if original_length > 80000:  # –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (>1.5 —á–∞—Å–∞ –≤–∏–¥–µ–æ)
            logger.info("üìö –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—é")
            text = self._smart_text_segmentation(text, 60000)
        elif original_length > 40000:  # –î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (>45 –º–∏–Ω –≤–∏–¥–µ–æ)
            logger.info("üìñ –î–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç - –±–µ—Ä–µ–º –∫–ª—é—á–µ–≤—ã–µ —á–∞—Å—Ç–∏")
            text = self._extract_key_parts(text, 35000)
        elif original_length > 20000:  # –°—Ä–µ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç (>20 –º–∏–Ω –≤–∏–¥–µ–æ)
            logger.info("üìÑ –°—Ä–µ–¥–Ω–∏–π —Ç–µ–∫—Å—Ç - –ª–µ–≥–∫–æ–µ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ")
            text = text[:18000] + "\n\n[...—á–∞—Å—Ç—å –ø—Ä–æ–ø—É—â–µ–Ω–∞...]\n\n" + text[-2000:]
        
        logger.info(f"‚úÇÔ∏è –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —É—á–µ–±–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –∏ –∏–∑–≤–ª–µ–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

–í–µ—Ä–Ω–∏ JSON –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ:
{{
  "main_topics": [
    {{
      "title": "–ö—Ä–∞—Ç–∫–æ–µ, –ø–æ–Ω—è—Ç–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã",
      "summary": "–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç–µ–º—ã —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)",
      "subtopics": ["–ü–æ–¥—Ç–µ–º–∞ 1", "–ü–æ–¥—Ç–µ–º–∞ 2"],
      "key_concepts": ["–ö–ª—é—á–µ–≤–æ–µ –ø–æ–Ω—è—Ç–∏–µ 1", "–ö–ª—é—á–µ–≤–æ–µ –ø–æ–Ω—è—Ç–∏–µ 2"],
      "complexity": "basic/intermediate/advanced",
      "examples": ["–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—Ä–∏–º–µ—Ä –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è"],
      "why_important": "–ü–æ—á–µ–º—É —ç—Ç–∞ —Ç–µ–º–∞ –≤–∞–∂–Ω–∞ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞"
    }}
  ],
  "concept_map": {{
    "relationships": [
      {{
        "from": "–¢–µ–º–∞ 1",
        "to": "–¢–µ–º–∞ 2", 
        "type": "causes/requires/similar/contrast/part_of",
        "description": "–ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–≤—è–∑–∏"
      }}
    ]
  }},
  "learning_objectives": ["–ß—Ç–æ —Å—Ç—É–¥–µ–Ω—Ç –¥–æ–ª–∂–µ–Ω –ø–æ–Ω—è—Ç—å –ø–æ—Å–ª–µ –∏–∑—É—á–µ–Ω–∏—è"],
  "prerequisites": ["–ß—Ç–æ –Ω—É–∂–Ω–æ –∑–Ω–∞—Ç—å –¥–æ –∏–∑—É—á–µ–Ω–∏—è —ç—Ç–æ–≥–æ –º–∞—Ç–µ—Ä–∏–∞–ª–∞"]
}}

–í–ê–ñ–ù–û:
1. –ù–ï –∫–æ–ø–∏—Ä—É–π —Ç–µ–∫—Å—Ç –¥–æ—Å–ª–æ–≤–Ω–æ! –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å–≤–æ–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
2. –°–æ–∑–¥–∞–π –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–º
3. –ò–∑–≤–ª–µ–∫–∏ 5-8 –≥–ª–∞–≤–Ω—ã—Ö —Ç–µ–º
4. –ö–∞–∂–¥–∞—è —Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ–π
5. –ü—Ä–∏–º–µ—Ä—ã –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –∏ –ø—Ä–∞–∫—Ç–∏—á–Ω—ã–º–∏

–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞: {text}"""
        
        response = self.openai_client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ —Å–æ–∑–¥–∞–Ω–∏—é —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤. –ò–∑–≤–ª–µ–∫–∞–π –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–µ —Ç–µ–º—ã, –∞ –Ω–µ –∫–æ–ø–∏—Ä—É–π —Ç–µ–∫—Å—Ç."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=2000,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 800
            timeout=30,  # –£–≤–µ–ª–∏—á–µ–Ω–æ —Å 20
            response_format={"type": "json_object"}
        )
        
        data = json.loads(response.choices[0].message.content)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è
        for topic in data.get("main_topics", []):
            topic.setdefault("subtopics", [])
            topic.setdefault("examples", [])
            topic.setdefault("why_important", "–í–∞–∂–Ω–∞—è —Ç–µ–º–∞")
        
        data.setdefault("learning_objectives", ["–ò–∑—É—á–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã"])
        data.setdefault("concept_map", {"relationships": []})
        data.setdefault("prerequisites", [])
        
        return data
    
    def _smart_text_segmentation(self, text: str, target_length: int) -> str:
        """–£–º–Ω–∞—è —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        try:
            # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            sentences = text.split('. ')
            
            # –ë–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ (40%), —Å–µ—Ä–µ–¥–∏–Ω—É (30%) –∏ –∫–æ–Ω–µ—Ü (30%)
            total_sentences = len(sentences)
            
            start_count = int(total_sentences * 0.4)
            middle_start = int(total_sentences * 0.35)
            middle_count = int(total_sentences * 0.3)
            end_start = int(total_sentences * 0.7)
            
            # –°–æ–±–∏—Ä–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —á–∞—Å—Ç–∏
            start_part = '. '.join(sentences[:start_count])
            middle_part = '. '.join(sentences[middle_start:middle_start + middle_count])
            end_part = '. '.join(sentences[end_start:])
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
            segmented_text = (
                start_part + 
                "\n\n[...–ø–µ—Ä–µ—Ö–æ–¥ –∫ —Å–µ—Ä–µ–¥–∏–Ω–µ –ª–µ–∫—Ü–∏–∏...]\n\n" + 
                middle_part + 
                "\n\n[...–ø–µ—Ä–µ—Ö–æ–¥ –∫ –∑–∞–∫–ª—é—á–µ–Ω–∏—é...]\n\n" + 
                end_part
            )
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ, –æ–±—Ä–µ–∑–∞–µ–º
            if len(segmented_text) > target_length:
                segmented_text = segmented_text[:target_length] + "\n\n[...—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω...]"
            
            logger.info(f"üìö –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è: {len(text)} ‚Üí {len(segmented_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return segmented_text
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –æ–±—Ä–µ–∑–∞–Ω–∏—é
            return text[:target_length] + "..."
    
    def _extract_key_parts(self, text: str, target_length: int) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —á–∞—Å—Ç–µ–π —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –ò—â–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã
            key_indicators = [
                '–≤–∞–∂–Ω–æ', '–≥–ª–∞–≤–Ω–æ–µ', '–æ—Å–Ω–æ–≤–Ω–æ–µ', '–∫–ª—é—á–µ–≤–æ–µ', '–∑–∞–∫–ª—é—á–µ–Ω–∏–µ', 
                '–∏—Ç–∞–∫', '—Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º', '–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ', '—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ',
                '–Ω–∞–ø—Ä–∏–º–µ—Ä', '–∫ –ø—Ä–∏–º–µ—Ä—É', '—Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º', '–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ',
                'first', 'second', 'third', 'finally', 'conclusion',
                'important', 'key', 'main', 'essential', 'summary'
            ]
            
            sentences = text.split('. ')
            key_sentences = []
            regular_sentences = []
            
            # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ –∏ –æ–±—ã—á–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            for sentence in sentences:
                sentence_lower = sentence.lower()
                if any(indicator in sentence_lower for indicator in key_indicators):
                    key_sentences.append(sentence)
                else:
                    regular_sentences.append(sentence)
            
            # –ù–∞—á–∏–Ω–∞–µ–º —Å –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
            result_text = '. '.join(key_sentences)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ã—á–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞
            if len(result_text) < target_length:
                remaining_length = target_length - len(result_text)
                
                # –ë–µ—Ä–µ–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü –æ–±—ã—á–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                if regular_sentences:
                    start_count = len(regular_sentences) // 3
                    end_count = len(regular_sentences) // 3
                    
                    additional_text = (
                        '. '.join(regular_sentences[:start_count]) + 
                        "\n\n[...–æ—Å–Ω–æ–≤–Ω–∞—è —á–∞—Å—Ç—å...]\n\n" +
                        '. '.join(regular_sentences[-end_count:])
                    )
                    
                    if len(additional_text) <= remaining_length:
                        result_text += "\n\n" + additional_text
                    else:
                        result_text += "\n\n" + additional_text[:remaining_length]
            
            logger.info(f"üìñ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —á–∞—Å—Ç–µ–π: {len(text)} ‚Üí {len(result_text)} —Å–∏–º–≤–æ–ª–æ–≤")
            return result_text
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∫–ª—é—á–µ–≤—ã—Ö —á–∞—Å—Ç–µ–π: {e}")
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –æ–±—Ä–µ–∑–∞–Ω–∏—é
            return text[:target_length] + "..."
    
    def _extract_topics_local(self, text: str) -> Dict[str, Any]:
        """–õ–æ–∫–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–º –±–µ–∑ API"""
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ —á–∞—Å—Ç–æ—Ç–Ω–æ—Å—Ç–∏ —Å–ª–æ–≤
        words = re.findall(r'\b[–∞-—è—ë]{4,}\b', text.lower())
        word_freq = Counter(words)
        
        topics = []
        for word, freq in word_freq.most_common(5):
            if freq > 2:
                topics.append({
                    "title": word.capitalize(),
                    "summary": f"–¢–µ–º–∞ —Å–≤—è–∑–∞–Ω–Ω–∞—è —Å {word}",
                    "subtopics": [],
                    "key_concepts": [word],
                    "complexity": "basic",
                    "examples": [],
                    "why_important": f"–ß–∞—Å—Ç–æ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è ({freq} —Ä–∞–∑)"
                })
        
        if not topics:
            topics = [{
                "title": "–û—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞ –≤–∏–¥–µ–æ",
                "summary": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤–∏–¥–µ–æ",
                "subtopics": [],
                "key_concepts": [],
                "complexity": "basic",
                "examples": [],
                "why_important": "–û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"
            }]
        
        return {
            "main_topics": topics,
            "learning_objectives": ["–ò–∑—É—á–∏—Ç—å –æ—Å–Ω–æ–≤–Ω—ã–µ —Ç–µ–º—ã"],
            "concept_map": {"relationships": []},
            "prerequisites": []
        }
    
    def _generate_summary_express(self, text: str) -> str:
        """–≠–∫—Å–ø—Ä–µ—Å—Å-—Ä–µ–∑—é–º–µ"""
        try:
            if self.openai_client and len(text) > 100:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
                if len(text) > 15000:
                    text = text[:15000] + "..."
                
                response = self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{
                        "role": "user", 
                        "content": f"–°–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (–º–∞–∫—Å–∏–º—É–º 150 —Å–ª–æ–≤):\n\n{text}"
                    }],
                    temperature=0.3,
                    max_tokens=300,
                    timeout=15
                )
                
                return response.choices[0].message.content.strip()
            else:
                # –ü—Ä–æ—Å—Ç–æ–µ —Ä–µ–∑—é–º–µ
                sentences = text.split('.')[:5]  # –ü–µ—Ä–≤—ã–µ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
                return "## –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n" + ". ".join(sentences) + "."
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Ä–µ–∑—é–º–µ: {e}")
            return "## –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\n–í–∏–¥–µ–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è."
    
    def _generate_flashcards_express(self, text: str, topics: List[Dict]) -> List[Dict]:
        """–≠–∫—Å–ø—Ä–µ—Å—Å —Ñ–ª–µ—à-–∫–∞—Ä—Ç—ã"""
        try:
            if self.openai_client and len(text) > 100:
                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
                if len(text) > 12000:
                    text = text[:12000] + "..."
                
                response = self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{
                        "role": "user",
                        "content": f"""–°–æ–∑–¥–∞–π 5 –ø—Ä–æ—Å—Ç—ã—Ö —Ñ–ª–µ—à-–∫–∞—Ä—Ç –ø–æ —Ç–µ–∫—Å—Ç—É –≤ JSON:
[{{"q": "–í–æ–ø—Ä–æ—Å", "a": "–û—Ç–≤–µ—Ç", "type": "definition", "difficulty": 1}}]

–¢–µ–∫—Å—Ç: {text}"""
                    }],
                    temperature=0.2,
                    max_tokens=800,
                    timeout=15,
                    response_format={"type": "json_object"}
                )
                
                content = response.choices[0].message.content
                if content.startswith('['):
                    cards = json.loads(content)
                else:
                    data = json.loads(content)
                    cards = data.get('flashcards', data.get('cards', []))
                
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –ø–æ–ª—è
                for i, card in enumerate(cards):
                    card.setdefault("hint", "–ü–æ–¥—Å–∫–∞–∑–∫–∞")
                    card.setdefault("related_topics", [])
                    card.setdefault("memory_hook", "–ó–∞–ø–æ–º–Ω–∏—Ç–µ")
                    card.setdefault("common_mistakes", "–ë—É–¥—å—Ç–µ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω—ã")
                    card.setdefault("text_reference", f"–ö–∞—Ä—Ç–∞ {i+1}")
                
                return cards[:5]
            else:
                # –ü—Ä–æ—Å—Ç—ã–µ –∫–∞—Ä—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–º
                cards = []
                for i, topic in enumerate(topics[:5]):
                    cards.append({
                        "type": "definition",
                        "q": f"–ß—Ç–æ —Ç–∞–∫–æ–µ {topic['title']}?",
                        "a": topic['summary'],
                        "difficulty": 1,
                        "hint": "–û—Å–Ω–æ–≤–Ω–∞—è —Ç–µ–º–∞",
                        "related_topics": [topic['title']],
                        "memory_hook": f"–ó–∞–ø–æ–º–Ω–∏—Ç–µ: {topic['title']}",
                        "common_mistakes": "–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏—Ç–µ",
                        "text_reference": f"–¢–µ–º–∞ {i+1}"
                    })
                return cards
                
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Ñ–ª–µ—à-–∫–∞—Ä—Ç: {e}")
            return [{
                "type": "basic",
                "q": "–ß—Ç–æ –∏–∑—É—á–∞–ª–æ—Å—å –≤ –≤–∏–¥–µ–æ?",
                "a": "–í–∞–∂–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
                "difficulty": 1,
                "hint": "–û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
                "related_topics": ["–í–∏–¥–µ–æ"],
                "memory_hook": "–ò–∑—É—á–µ–Ω–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª",
                "common_mistakes": "–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏—Ç–µ",
                "text_reference": "–û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ"
            }]
    
    def _generate_mind_map_simple(self, topics: List[Dict]) -> Dict:
        """–ü—Ä–æ—Å—Ç–∞—è –º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∫–∞—Ä—Ç–∞"""
        branches = []
        colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FECA57"]
        
        for i, topic in enumerate(topics[:5]):
            branches.append({
                "name": topic['title'][:30],
                "importance": 0.9 - (i * 0.1),
                "color": colors[i % len(colors)],
                "children": [{"name": concept[:20], "importance": 0.5, "color": colors[i % len(colors)]} 
                           for concept in topic.get('key_concepts', [])[:3]]
            })
        
        return {
            "central_topic": topics[0]['title'] if topics else "–í–∏–¥–µ–æ",
            "branches": branches
        }
    
    def _generate_study_plan_simple(self, topics: List[Dict], flashcard_count: int) -> Dict:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è —Å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é"""
        main_topic = topics[0] if topics else {"title": "–í–∏–¥–µ–æ", "complexity": "basic"}
        
        return {
            "sessions": [{
                "session_number": 1,
                "date": datetime.now().strftime("%d.%m.%Y"),
                "duration_minutes": 30,
                "topics": [topic['title'] for topic in topics[:3]],
                "focus": "–ò–∑—É—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–µ–º",
                "exercises": ["–ü—Ä–æ—Å–º–æ—Ç—Ä –≤–∏–¥–µ–æ", "–ò–∑—É—á–µ–Ω–∏–µ —Ñ–ª–µ—à-–∫–∞—Ä—Ç", "–ü–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ"],
                "flashcards_count": flashcard_count,
                "main_topic": main_topic,  # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —à–∞–±–ª–æ–Ω–æ–º
                "phase_name": "–û—Å–Ω–æ–≤—ã",
                "activities": []
            }],
            "milestones": [{
                "title": "–ò–∑—É—á–∏—Ç—å –≤–∏–¥–µ–æ",
                "progress_percent": 100,
                "session": 1,
                "description": "–û—Å–Ω–æ–≤–Ω–æ–µ –∏–∑—É—á–µ–Ω–∏–µ"
            }],
            "review_schedule": [1, 3, 7],
            "total_hours": 0.5,
            "completion_date": (datetime.now() + timedelta(days=3)).strftime("%d.%m.%Y"),
            "difficulty_level": 1.2,  # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å —à–∞–±–ª–æ–Ω–æ–º
            "material_analysis": {
                "overall_difficulty": 1.5,
                "estimated_study_time": {
                    "total_hours": 0.5,
                    "study_time": 20,
                    "review_time": 10,
                    "reading_time": 0
                }
            },
            "adaptive_features": {
                "difficulty_adjustment": False,
                "personalized_pace": True,
                "progress_tracking": True
            },
            "success_metrics": {
                "target_retention": 80,
                "target_completion": 85,
                "target_satisfaction": 8
            }
        }
    
    def _assess_quality_simple(self, text: str, topics: List[Dict]) -> Dict:
        """–ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞"""
        return {
            "depth_score": min(0.8, len(topics) / 5),
            "coverage_score": min(0.8, len(text) / 1000),
            "practical_score": 0.6,
            "clarity_score": 0.7,
            "overall_score": 0.7,
            "suggestions": ["–ú–∞—Ç–µ—Ä–∏–∞–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤ —ç–∫—Å–ø—Ä–µ—Å—Å-—Ä–µ–∂–∏–º–µ"]
        }

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º
def process_video_fast(filepath: str, filename: str) -> Dict[str, Any]:
    """–ë—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ - –æ—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    processor = FastVideoProcessor()
    return processor.process_video_express(filepath, filename)

if __name__ == "__main__":
    # –¢–µ—Å—Ç
    import sys
    if len(sys.argv) > 1:
        test_file = sys.argv[1]
        if os.path.exists(test_file):
            result = process_video_fast(test_file, os.path.basename(test_file))
            print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {result['metadata']['processing_time']}—Å")
            print(f"–ù–∞–π–¥–µ–Ω–æ —Ç–µ–º: {len(result['topics_data']['main_topics'])}")
            print(f"–°–æ–∑–¥–∞–Ω–æ –∫–∞—Ä—Ç: {len(result['flashcards'])}")
        else:
            print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_file}")
    else:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python fast_video_processor.py <–ø—É—Ç—å_–∫_–≤–∏–¥–µ–æ>")